{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook fine-tunes the GPT model and also uses the BERT model to do the ultimate lyrics generation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Importing Required Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:12:35.635684Z",
     "start_time": "2023-04-20T19:12:17.734053Z"
    },
    "execution": {
     "iopub.execute_input": "2023-04-17T02:54:24.541082Z",
     "iopub.status.busy": "2023-04-17T02:54:24.540300Z",
     "iopub.status.idle": "2023-04-17T02:54:35.216917Z",
     "shell.execute_reply": "2023-04-17T02:54:35.215653Z",
     "shell.execute_reply.started": "2023-04-17T02:54:24.541037Z"
    },
    "id": "c12US8AgYli-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, GPT2LMHeadModel, AdamW, BertForNextSentencePrediction, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Some Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:12:35.791940Z",
     "start_time": "2023-04-20T19:12:35.635684Z"
    },
    "execution": {
     "iopub.execute_input": "2023-04-17T02:54:35.219850Z",
     "iopub.status.busy": "2023-04-17T02:54:35.218790Z",
     "iopub.status.idle": "2023-04-17T02:54:35.232357Z",
     "shell.execute_reply": "2023-04-17T02:54:35.231335Z",
     "shell.execute_reply.started": "2023-04-17T02:54:35.219801Z"
    },
    "id": "cEb9trPYaDd-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "random.seed(17)\n",
    "np.random.seed(17)\n",
    "torch.manual_seed(17)\n",
    "torch.cuda.manual_seed_all(17)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:12:37.891044Z",
     "start_time": "2023-04-20T19:12:35.807683Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "execution": {
     "iopub.execute_input": "2023-04-17T02:54:44.374192Z",
     "iopub.status.busy": "2023-04-17T02:54:44.373628Z",
     "iopub.status.idle": "2023-04-17T02:54:44.552207Z",
     "shell.execute_reply": "2023-04-17T02:54:44.551175Z",
     "shell.execute_reply.started": "2023-04-17T02:54:44.374115Z"
    },
    "id": "gN4q0G2Df89O",
    "outputId": "f89f5847-e659-447f-b58e-de9cd7b9cd1b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "raps = df[\"rap\"].values.tolist()\n",
    "rappers = df[\"rapper\"].unique().tolist()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setting Special Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:12:37.906681Z",
     "start_time": "2023-04-20T19:12:37.891044Z"
    }
   },
   "outputs": [],
   "source": [
    "beginning_of_sentence_token = '<bos>'\n",
    "end_of_sentence_token = '<eos>'\n",
    "pad_token = '<pad>'\n",
    "unknown_token = '<unk>'\n",
    "start_of_rap_token = \"<|rap_start|>\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configuring Tokenizer and Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:12:40.024833Z",
     "start_time": "2023-04-20T19:12:37.906681Z"
    },
    "execution": {
     "iopub.execute_input": "2023-04-17T02:54:44.555238Z",
     "iopub.status.busy": "2023-04-17T02:54:44.554546Z",
     "iopub.status.idle": "2023-04-17T02:54:51.407465Z",
     "shell.execute_reply": "2023-04-17T02:54:51.406252Z",
     "shell.execute_reply.started": "2023-04-17T02:54:44.555184Z"
    },
    "id": "RdnnYyAeEt5H",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"HooshvareLab/gpt2-fa\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    bos_token=beginning_of_sentence_token,\n",
    "    eos_token=end_of_sentence_token,\n",
    "    pad_token=pad_token,\n",
    "    unk_token=unknown_token\n",
    ")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    bos_token_id=tokenizer(beginning_of_sentence_token)[\"input_ids\"][0],\n",
    "    eos_token_id=tokenizer(end_of_sentence_token)[\"input_ids\"][0],\n",
    "    pad_token_id=tokenizer(pad_token)[\"input_ids\"][0],\n",
    "    unk_token_id=tokenizer(unknown_token)[\"input_ids\"][0],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Defining Class For Managing The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:12:40.040464Z",
     "start_time": "2023-04-20T19:12:40.024833Z"
    },
    "execution": {
     "iopub.execute_input": "2023-04-17T02:54:51.415069Z",
     "iopub.status.busy": "2023-04-17T02:54:51.412622Z",
     "iopub.status.idle": "2023-04-17T02:54:51.425907Z",
     "shell.execute_reply": "2023-04-17T02:54:51.424702Z",
     "shell.execute_reply.started": "2023-04-17T02:54:51.415026Z"
    },
    "id": "C5m3YNOvIKoU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RapDataset(Dataset):\n",
    "\n",
    "    def __init__(self, raps, tokenizer, max_length=1024):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.attention_masks = []\n",
    "\n",
    "        for rap in raps:\n",
    "            encodings_dict = tokenizer(beginning_of_sentence_token + rap + end_of_sentence_token,\n",
    "                                       truncation=True,\n",
    "                                       max_length=max_length,\n",
    "                                       padding=\"max_length\")\n",
    "\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attention_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attention_masks[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Splitting Train & Val Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:12:45.143015Z",
     "start_time": "2023-04-20T19:12:40.040464Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2023-04-17T02:54:51.434353Z",
     "iopub.status.busy": "2023-04-17T02:54:51.431663Z",
     "iopub.status.idle": "2023-04-17T02:54:51.565131Z",
     "shell.execute_reply": "2023-04-17T02:54:51.561173Z",
     "shell.execute_reply.started": "2023-04-17T02:54:51.434312Z"
    },
    "id": "MwY3srMLINfs",
    "outputId": "c9fa0a26-7544-4528-fe21-5c2f7ef87c2f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_length = 32\n",
    "dataset = RapDataset(raps, tokenizer, max_length=max_length)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [0.9, 0.1])\n",
    "\n",
    "print(f'Train Dataset Size: {len(train_dataset)}, Validation Dataset Size: {len(val_dataset)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configuring Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:12:45.189910Z",
     "start_time": "2023-04-20T19:12:45.143015Z"
    },
    "execution": {
     "iopub.status.busy": "2023-04-17T02:54:51.568489Z",
     "iopub.status.idle": "2023-04-17T02:54:51.571110Z",
     "shell.execute_reply": "2023-04-17T02:54:51.570849Z",
     "shell.execute_reply.started": "2023-04-17T02:54:51.570818Z"
    },
    "id": "8hxgySomITYV",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=SequentialSampler(val_dataset),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Getting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:12:49.985760Z",
     "start_time": "2023-04-20T19:12:45.158626Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2023-04-17T02:54:51.575488Z",
     "iopub.status.idle": "2023-04-17T02:54:51.578099Z",
     "shell.execute_reply": "2023-04-17T02:54:51.577859Z",
     "shell.execute_reply.started": "2023-04-17T02:54:51.577829Z"
    },
    "id": "TVUEzpPvIYYV",
    "outputId": "64b45872-b201-466c-a573-e68fdb5ac63d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(model_name, config=config)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configuring Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:12:50.001375Z",
     "start_time": "2023-04-20T19:12:49.985760Z"
    },
    "execution": {
     "iopub.status.busy": "2023-04-17T02:54:51.582483Z",
     "iopub.status.idle": "2023-04-17T02:54:51.583375Z",
     "shell.execute_reply": "2023-04-17T02:54:51.583106Z",
     "shell.execute_reply.started": "2023-04-17T02:54:51.583077Z"
    },
    "id": "uiWGu9MsIcw8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "learning_rate = 5e-5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8, no_deprecation_warning=True)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(train_dataloader) * epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:18:38.539913Z",
     "start_time": "2023-04-20T19:12:50.001375Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2023-04-17T02:54:51.584925Z",
     "iopub.status.idle": "2023-04-17T02:54:51.585799Z",
     "shell.execute_reply": "2023-04-17T02:54:51.585538Z",
     "shell.execute_reply.started": "2023-04-17T02:54:51.585510Z"
    },
    "id": "m-X-YWgdIgcT",
    "outputId": "5001856f-c6dc-4137-83e3-985cdbbab109",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        batch_input_ids = batch[0].to(device)\n",
    "        batch_labels = batch[0].to(device)\n",
    "        batch_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        res = model(batch_input_ids,\n",
    "                    attention_mask=batch_masks,\n",
    "                    labels=batch_labels,\n",
    "                    return_dict=True)\n",
    "\n",
    "        batch_loss = res.loss\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "\n",
    "        batch_input_ids = batch[0].to(device)\n",
    "        batch_labels = batch[0].to(device)\n",
    "        batch_masks = batch[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            res = model(batch_input_ids,\n",
    "                        attention_mask=batch_masks,\n",
    "                        labels=batch_labels,\n",
    "                        return_dict=True)\n",
    "\n",
    "        batch_loss = res.loss\n",
    "        val_loss += batch_loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f'Epoch Training Loss: {avg_train_loss}')\n",
    "    print(f'Epoch Validation loss: {avg_val_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plotting Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:18:40.711456Z",
     "start_time": "2023-04-20T19:18:38.546145Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "execution": {
     "iopub.status.busy": "2023-04-17T02:54:51.591736Z",
     "iopub.status.idle": "2023-04-17T02:54:51.592653Z",
     "shell.execute_reply": "2023-04-17T02:54:51.592383Z",
     "shell.execute_reply.started": "2023-04-17T02:54:51.592352Z"
    },
    "id": "uzzFo1-zIhna",
    "outputId": "b50b476a-0a5d-4199-dae4-a384f965e79b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Defining a couple of Functions for Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:29:49.647250Z",
     "start_time": "2023-04-20T19:29:49.631630Z"
    },
    "execution": {
     "iopub.status.busy": "2023-04-17T02:54:51.594234Z",
     "iopub.status.idle": "2023-04-17T02:54:51.595052Z",
     "shell.execute_reply": "2023-04-17T02:54:51.594810Z",
     "shell.execute_reply.started": "2023-04-17T02:54:51.594783Z"
    },
    "id": "Dh2FAX8CJueV",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_generated_text(text):\n",
    "    return re.sub(\"\\n+\", \"\\n\", text.replace(beginning_of_sentence_token, \"\").replace(end_of_sentence_token, \"\").replace(\"<sep>\", \"\\n\").replace(start_of_rap_token, '\\n'))\n",
    "\n",
    "def generate(base_text, max_length=128, num_return_sequences=3):\n",
    "    model.eval()\n",
    "\n",
    "    base = torch.tensor(tokenizer.encode(base_text)).unsqueeze(0).to(device)\n",
    "\n",
    "    generated_output = model.generate(\n",
    "        base,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        max_length=max_length,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=num_return_sequences\n",
    "    )\n",
    "\n",
    "    generated_raps = []\n",
    "    for output in generated_output:\n",
    "        generated_rap = tokenizer.decode(output, skip_special_tokens=False)\n",
    "        generated_rap = clean_generated_text(generated_rap)\n",
    "        generated_raps.append(generated_rap)\n",
    "\n",
    "    return generated_raps\n",
    "\n",
    "def find_candidates_with_lowest_common_words(candidates, previous_candidate_with_max_prob, num_of_candidates_to_choose=3):\n",
    "    previous_sentence_words = set(previous_candidate_with_max_prob.split(\" \"))\n",
    "    candidates_words = {candidate: set(candidate.split(\" \")) for candidate in candidates}\n",
    "    common_words_num = {}\n",
    "    for candidate in candidates:\n",
    "        candidate_words = candidates_words[candidate]\n",
    "        num_of_common_words = 0\n",
    "        for word in candidate_words:\n",
    "            if word in previous_sentence_words:\n",
    "                num_of_common_words += 1\n",
    "        if num_of_common_words not in common_words_num:\n",
    "            common_words_num[num_of_common_words] = []\n",
    "        common_words_num[num_of_common_words].append(candidate)\n",
    "\n",
    "    nums = list(common_words_num.keys())\n",
    "    sorted(nums)\n",
    "\n",
    "    chosen_candidates = []\n",
    "    for num in nums:\n",
    "        list_of_cans = common_words_num[num]\n",
    "        for cans in list_of_cans:\n",
    "            chosen_candidates.append(cans)\n",
    "            if len(chosen_candidates) == num_of_candidates_to_choose:\n",
    "                return chosen_candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Getting The Bert Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:18:53.912113Z",
     "start_time": "2023-04-20T19:18:40.726958Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bert_model_name = \"HooshvareLab/bert-base-parsbert-uncased\"\n",
    "bert_model = BertForNextSentencePrediction.from_pretrained(\"models/bert_model\").to(device)\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generating The Final Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T19:35:45.504413Z",
     "start_time": "2023-04-20T19:34:31.772468Z"
    },
    "execution": {
     "iopub.status.busy": "2023-04-17T02:54:51.605126Z",
     "iopub.status.idle": "2023-04-17T02:54:51.605963Z",
     "shell.execute_reply": "2023-04-17T02:54:51.605725Z",
     "shell.execute_reply.started": "2023-04-17T02:54:51.605697Z"
    },
    "id": "wsB-3HZCNbaE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_of_lines = 15\n",
    "num_of_candidates_to_consider = 10\n",
    "rapper = rappers[np.random.randint(0, len(rappers))]\n",
    "base_text = f\"{beginning_of_sentence_token}{rapper}{start_of_rap_token}\"\n",
    "previous_candidate_with_max_prob = None\n",
    "\n",
    "for i in range(num_of_lines):\n",
    "    generated_raps = generate(base_text, num_return_sequences=num_of_candidates_to_consider)\n",
    "\n",
    "    candidates = []\n",
    "    for generated_rap in generated_raps:\n",
    "        generated_rap_lines = generated_rap.split(\"\\n\")\n",
    "        candidates.append(generated_rap_lines[i])\n",
    "\n",
    "    candidates = find_candidates_with_lowest_common_words(candidates, previous_candidate_with_max_prob) if previous_candidate_with_max_prob is not None else candidates\n",
    "\n",
    "    if i == 0:\n",
    "        previous_candidate_with_max_prob = base_text\n",
    "    else:\n",
    "        max_prob, candidate_with_max_prob = -math.inf, \"\"\n",
    "\n",
    "        for candidate in candidates:\n",
    "            encoding = bert_tokenizer.encode_plus(previous_candidate_with_max_prob, candidate,\n",
    "                                                  add_special_tokens=True,\n",
    "                                                  max_length=128,\n",
    "                                                  padding=\"max_length\",\n",
    "                                                  return_tensors=\"pt\")\n",
    "\n",
    "            input_ids = encoding[\"input_ids\"].to(device)\n",
    "            token_type_ids = encoding[\"token_type_ids\"].to(device)\n",
    "            attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                res = bert_model(input_ids,\n",
    "                                 token_type_ids=token_type_ids,\n",
    "                                 attention_mask=attention_mask,\n",
    "                                 return_dict=True)\n",
    "\n",
    "            prob = res.logits.detach().cpu().numpy()[0][0]\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                candidate_with_max_prob = candidate\n",
    "\n",
    "        base_text += candidate_with_max_prob + \"<sep>\"\n",
    "        previous_candidate_with_max_prob = candidate_with_max_prob\n",
    "\n",
    "print(clean_generated_text(base_text))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
